### ワークロードのリソース使用量の管理

Kubernetesプラットフォームは、多くの仮想化および抽象化レイヤーの上に構築されていますが、ワークロードが使用しているリソースを意識する必要があります。

これは、Kubernetesが通常、共有インフラ上で動作するプラットフォームとして設計されているため、あなたが使用するリソースの量が、同じクラスタ上で動作する他のアプリケーションに影響を与える可能性があるためです。

### シナリオ
- Kubernetesプラットフォームの管理者は、プロジェクト（名前空間）が遵守する必要のあるリソースクォータを設定します。
- アプリケーションチームは、指定されたリソースを異なるマイクロサービスに割り当てる責任があります。
- 以下のコマンドを実行して、このデプロイメントを適用します。

  ```bash
  cd sockshop
  ./deploy_newbuild.sh
  ```

あなたのDynatraceコンソールから目を離さないでください...何が起こるかわかりません。

ある時、appsチームとk8s infraチームの両方が、Dynatraceからのアラートを受け取りました。それを見てみましょう。

![oomkill-container](../assets/k8s/oomkill-problemcard1.png)

Negative
: 何が起こったのでしょうか？どの**service**に影響がありましたか？どの**namespace**で起きましたか？

新しいカートサービスポッドのコンテナが**OOMKilled**されました。これは、メモリ使用量が設定された上限を超えたことを意味します。今日まで、OOMKilledの問題は発生していませんでした。

コンテナをクリックすると、コンテナービューにドリルダウンします。

![oomkill-container](../assets/k8s/oomkill-problemcard2.png)

コンテナビューには、リソースの消費状況を明確に把握するために必要なすべてのメトリクスとデータポイントが表示されます。

![oomkill-memory](../assets/k8s/oomkill-memory.png)  

これは新しいビルドと関係があり、次のどちらかが問題の原因となります。

1. コンテナのメモリ制限が間違って設定されていた
2. 新しいビルドにメモリリークがあり、時間の経過とともに制限値以上のメモリを消費している。
   - このような場合、いくらメモリ制限を増やしても、結局は制限を超えてしまいます。これでは時間稼ぎをしているだけで、コード自体を修正する必要があります。
   - さまざまな条件でテストを行い、Javaのメモリメトリクスをプロセスビューから監視します。Dynatraceは、必要となるすべてのメトリクスを提供しています。

   ![oomkill-memory](../assets/k8s/oomkill-memory-trends.png)

開発チームはすぐにこの問題を発見し、修正を行いました。この問題は、設定上の問題に関連しています。コンテナのメモリ制限が誤って設定されていました。

ターミナルでは、修正を適用するために実行します。

```bash
kubectl apply -f ~/sockshop/manifests/sockshop-app/newbuilds/newbuild-quota-fix.yml
```

### 教訓として
- Kubernetesにおけるリソース管理は重要です。
- インフラやクラウドサービスでは、リソースは常に制限されており、コストがかかります。
- ワークロードのリソース消費量を把握することは、様々なサービスに対してどのような要求や制限を設定すべきかを把握するための鍵となります。

k8sのインフラ運用チームは、常に必要な分だけのリソースを提供してくれます。彼らの責任は、プラットフォームを利用するすべての人のために、プラットフォームが健全に保たれるようにすることです。そのため、より多くのリソースが必要な場合には、プラットフォームチームと交渉しなければなりません。どのような交渉でも、できるだけ多くの情報を持ってテーブルにつくことが大切です。

そのためには、Dynatraceが頼りになります。